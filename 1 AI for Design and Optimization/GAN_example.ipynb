{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8bfc2b9-969b-4b0e-bf41-e947a661ce1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faf7a706-2bed-4e53-a8f4-0ef5d28e5f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55f5c308-72e0-4fd3-afa2-793cad0f84e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Generator with fewer layers and smaller output size (14x14)\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, output_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Define the Discriminator with smaller architecture\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc751609-27f5-44ea-8d1e-860ed3fdc951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "latent_dim = 100\n",
    "img_size = 14 * 14  # Reduced image size (14x14)\n",
    "batch_size = 64\n",
    "learning_rate = 0.0002\n",
    "num_epochs = 20  # Fewer epochs for faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1b3c043-7855-4219-995c-61928fc62526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the Data with image resizing to 14x14\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(14),  # Resize images to 14x14\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "921f4589-2829-41fb-b7ef-e7096a917198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models, loss function, and optimizers\n",
    "generator = Generator(input_dim=latent_dim, output_dim=img_size)#.to('cuda')\n",
    "discriminator = Discriminator(input_dim=img_size)#.to('cuda')\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ddea90-d0a5-4f80-9046-6337d963b8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/20] Batch 0/938                   Loss D: 0.6944909691810608, loss G: 0.6663005352020264\n",
      "Epoch [0/20] Batch 100/938                   Loss D: 0.43638157844543457, loss G: 0.8418830633163452\n",
      "Epoch [0/20] Batch 200/938                   Loss D: 0.2129601538181305, loss G: 1.5444729328155518\n",
      "Epoch [0/20] Batch 300/938                   Loss D: 0.042432673275470734, loss G: 2.9464690685272217\n",
      "Epoch [0/20] Batch 400/938                   Loss D: 0.05790332332253456, loss G: 3.221752643585205\n",
      "Epoch [0/20] Batch 500/938                   Loss D: 0.2738586664199829, loss G: 1.957188606262207\n",
      "Epoch [0/20] Batch 600/938                   Loss D: 0.18735262751579285, loss G: 2.431997776031494\n",
      "Epoch [0/20] Batch 700/938                   Loss D: 0.06466732919216156, loss G: 2.658564567565918\n",
      "Epoch [0/20] Batch 800/938                   Loss D: 0.18078076839447021, loss G: 2.133993625640869\n",
      "Epoch [0/20] Batch 900/938                   Loss D: 0.08678928017616272, loss G: 2.431356906890869\n",
      "Epoch [1/20] Batch 0/938                   Loss D: 0.13506241142749786, loss G: 2.0092482566833496\n",
      "Epoch [1/20] Batch 100/938                   Loss D: 0.1326543688774109, loss G: 2.878849983215332\n",
      "Epoch [1/20] Batch 200/938                   Loss D: 0.32047781348228455, loss G: 1.9156696796417236\n",
      "Epoch [1/20] Batch 300/938                   Loss D: 0.34108036756515503, loss G: 2.337188482284546\n",
      "Epoch [1/20] Batch 400/938                   Loss D: 0.36277782917022705, loss G: 1.6556464433670044\n",
      "Epoch [1/20] Batch 500/938                   Loss D: 0.45928144454956055, loss G: 1.9496464729309082\n",
      "Epoch [1/20] Batch 600/938                   Loss D: 0.2111252248287201, loss G: 1.720333218574524\n",
      "Epoch [1/20] Batch 700/938                   Loss D: 0.23925510048866272, loss G: 1.8561471700668335\n",
      "Epoch [1/20] Batch 800/938                   Loss D: 0.26055243611335754, loss G: 1.950089931488037\n",
      "Epoch [1/20] Batch 900/938                   Loss D: 0.3235403299331665, loss G: 2.2921102046966553\n",
      "Epoch [2/20] Batch 0/938                   Loss D: 0.44722306728363037, loss G: 1.5937609672546387\n",
      "Epoch [2/20] Batch 100/938                   Loss D: 0.2600993812084198, loss G: 1.7261302471160889\n",
      "Epoch [2/20] Batch 200/938                   Loss D: 0.2153383046388626, loss G: 1.668852686882019\n",
      "Epoch [2/20] Batch 300/938                   Loss D: 0.24579092860221863, loss G: 1.540237545967102\n",
      "Epoch [12/20] Batch 600/938                   Loss D: 0.27940255403518677, loss G: 3.2023608684539795\n",
      "Epoch [12/20] Batch 700/938                   Loss D: 0.43030422925949097, loss G: 2.000308036804199\n",
      "Epoch [12/20] Batch 800/938                   Loss D: 0.30867964029312134, loss G: 2.403874158859253\n",
      "Epoch [12/20] Batch 900/938                   Loss D: 0.35270240902900696, loss G: 2.081601858139038\n",
      "Epoch [13/20] Batch 0/938                   Loss D: 0.23792704939842224, loss G: 2.4913859367370605\n",
      "Epoch [13/20] Batch 100/938                   Loss D: 0.24811804294586182, loss G: 1.6580407619476318\n",
      "Epoch [13/20] Batch 200/938                   Loss D: 0.18970146775245667, loss G: 2.9341986179351807\n",
      "Epoch [13/20] Batch 300/938                   Loss D: 0.4133911728858948, loss G: 2.1522574424743652\n",
      "Epoch [13/20] Batch 400/938                   Loss D: 0.3692341446876526, loss G: 2.140723466873169\n",
      "Epoch [13/20] Batch 500/938                   Loss D: 0.26852715015411377, loss G: 3.2385215759277344\n",
      "Epoch [13/20] Batch 600/938                   Loss D: 0.3009639382362366, loss G: 2.3769919872283936\n",
      "Epoch [13/20] Batch 700/938                   Loss D: 0.4386008381843567, loss G: 2.553706169128418\n",
      "Epoch [13/20] Batch 800/938                   Loss D: 0.2596273422241211, loss G: 2.0734550952911377\n",
      "Epoch [13/20] Batch 900/938                   Loss D: 0.23468482494354248, loss G: 3.079526901245117\n",
      "Epoch [14/20] Batch 0/938                   Loss D: 0.45251065492630005, loss G: 1.7046661376953125\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (imgs, _) in enumerate(train_loader):\n",
    "        \n",
    "        # Adversarial ground truths\n",
    "        valid = torch.ones((imgs.size(0), 1), requires_grad=False)#.to('cuda')\n",
    "        fake = torch.zeros((imgs.size(0), 1), requires_grad=False)#.to('cuda')\n",
    "        \n",
    "        # Configure input\n",
    "        real_imgs = imgs.view(imgs.size(0), -1)#.to('cuda')\n",
    "        \n",
    "        # Train Generator\n",
    "        optimizer_G.zero_grad()\n",
    "        z = torch.randn((imgs.size(0), latent_dim))#.to('cuda')\n",
    "        gen_imgs = generator(z)\n",
    "        g_loss = criterion(discriminator(gen_imgs), valid)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        real_loss = criterion(discriminator(real_imgs), valid)\n",
    "        fake_loss = criterion(discriminator(gen_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Print progress\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}/{num_epochs}] Batch {i}/{len(train_loader)} \\\n",
    "                  Loss D: {d_loss.item()}, loss G: {g_loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f8aace-b34a-4dfb-b6f2-62c946cb0809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Generated and Original Images\n",
    "def show_images(gen_images, real_images):\n",
    "    gen_images = gen_images.view(gen_images.size(0), 1, 14, 14).cpu().data\n",
    "    real_images = real_images.view(real_images.size(0), 1, 14, 14).cpu().data\n",
    "    \n",
    "    # Concatenate generated and real images\n",
    "    images = torch.cat([gen_images, real_images])\n",
    "    \n",
    "    grid = torchvision.utils.make_grid(images, nrow=8, normalize=True)\n",
    "    \n",
    "    # Set smaller figure size\n",
    "    plt.figure(figsize=(6, 6))  # Smaller figure\n",
    "    plt.imshow(grid.permute(1, 2, 0))\n",
    "    plt.title('Top Half: Generated Images, Bottom Half: Original Images')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Generate images\n",
    "z = torch.randn(16, latent_dim)#.to('cuda')  # Reduced to 16 for a smaller plot\n",
    "gen_imgs = generator(z)\n",
    "\n",
    "# Get a batch of real images\n",
    "real_imgs, _ = next(iter(train_loader))\n",
    "real_imgs = real_imgs[:16].view(16, -1)#.to('cuda')  # Reduced to 16 for a smaller plot\n",
    "\n",
    "# Show generated vs original images\n",
    "show_images(gen_imgs, real_imgs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
